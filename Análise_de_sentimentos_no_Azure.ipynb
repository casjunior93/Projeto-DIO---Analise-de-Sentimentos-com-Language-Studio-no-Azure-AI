{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP62900IFXRKQmwLB9dI5u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casjunior93/Projeto-DIO---Analise-de-Sentimentos-com-Language-Studio-no-Azure-AI/blob/main/An%C3%A1lise_de_sentimentos_no_Azure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando o SDK para análise de texto"
      ],
      "metadata": {
        "id": "j8ulK4DmqfiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute na primeira vez que iniciar o notebook. Depois pode comentar colocando um # na frente"
      ],
      "metadata": {
        "id": "__l9aqUGq2cr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_g9PpvCqSkH"
      },
      "outputs": [],
      "source": [
        "!pip install azure-ai-textanalytics==5.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora importamos o que vamos precisar usar do SDK:"
      ],
      "metadata": {
        "id": "BfkNswmnsWjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential"
      ],
      "metadata": {
        "id": "TQb95-Qjsgxz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Informe aqui a chave de assinatura e o ponto final (endpoint). Podem ser obtidos na página do recurso em \"Chaves e Ponto Ponto Final\" no Portal do Azure, ou, dentro do Estúdio de linguagem\", em Language Studio > Classify text > Analyze sentiment and mine opinions, no final da página."
      ],
      "metadata": {
        "id": "CT7Wg0bEq-Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_key = \"SUA CHAVE\"\n",
        "language_endpoint = \"SEU PONTO FINAL\""
      ],
      "metadata": {
        "id": "mI3Nu89LsAHh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos nos autenticar usando a chave e o ponto final:"
      ],
      "metadata": {
        "id": "g1cArMsxsnse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def authenticate_client():\n",
        "    ta_credential = AzureKeyCredential(language_key)\n",
        "    text_analytics_client = TextAnalyticsClient(\n",
        "            endpoint=language_endpoint,\n",
        "            credential=ta_credential)\n",
        "    return text_analytics_client\n",
        "\n",
        "client = authenticate_client()"
      ],
      "metadata": {
        "id": "05eV0KOIsnGH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa é a função para detectar sentimentos e opiniões que vamos utilizar:"
      ],
      "metadata": {
        "id": "sFGN-tths9bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis_with_opinion_mining_example(client, documents):\n",
        "\n",
        "    ''' documents = [\n",
        "        \"The food and service were unacceptable. The concierge was nice, however.\"\n",
        "    ] '''\n",
        "\n",
        "    result = client.analyze_sentiment(documents, show_opinion_mining=True)\n",
        "    doc_result = [doc for doc in result if not doc.is_error]\n",
        "\n",
        "    positive_reviews = [doc for doc in doc_result if doc.sentiment == \"positive\"]\n",
        "    negative_reviews = [doc for doc in doc_result if doc.sentiment == \"negative\"]\n",
        "\n",
        "    positive_mined_opinions = []\n",
        "    mixed_mined_opinions = []\n",
        "    negative_mined_opinions = []\n",
        "\n",
        "    for document in doc_result:\n",
        "        print(\"Sentimento do documento: {}\".format(document.sentiment))\n",
        "        print(\"Pontuações gerais: Positivo={0:.2f}; Neutro={1:.2f}; Negativo={2:.2f} \\n\".format(\n",
        "            document.confidence_scores.positive,\n",
        "            document.confidence_scores.neutral,\n",
        "            document.confidence_scores.negative,\n",
        "        ))\n",
        "        for sentence in document.sentences:\n",
        "            print(\"Sentença: {}\".format(sentence.text))\n",
        "            print(\"Sentimento da sentença: {}\".format(sentence.sentiment))\n",
        "            print(\"Pontuação da sentença:\\nPositivo={0:.2f}\\nNeutro={1:.2f}\\nNegativo={2:.2f}\\n\".format(\n",
        "                sentence.confidence_scores.positive,\n",
        "                sentence.confidence_scores.neutral,\n",
        "                sentence.confidence_scores.negative,\n",
        "            ))\n",
        "            for mined_opinion in sentence.mined_opinions:\n",
        "                target = mined_opinion.target\n",
        "                print(\"......'{}' target '{}'\".format(target.sentiment, target.text))\n",
        "                print(\"......Pontuação alvo:\\n......Positivo={0:.2f}\\n......Negativo={1:.2f}\\n\".format(\n",
        "                    target.confidence_scores.positive,\n",
        "                    target.confidence_scores.negative,\n",
        "                ))\n",
        "                for assessment in mined_opinion.assessments:\n",
        "                    print(\"......'{}' assessment '{}'\".format(assessment.sentiment, assessment.text))\n",
        "                    print(\"......Pontuação da avaliação:\\n......Positivo={0:.2f}\\n......Negativo={1:.2f}\\n\".format(\n",
        "                        assessment.confidence_scores.positive,\n",
        "                        assessment.confidence_scores.negative,\n",
        "                    ))\n",
        "        print(\"\\n\")\n",
        "        print('------------------------------------')"
      ],
      "metadata": {
        "id": "ToKZ0xvjtCIR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos criar uma lista com opiniões:"
      ],
      "metadata": {
        "id": "7OmHIPOntH57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_positivo = \"Estou encantado com meu novo Lenovo G40-70! Sua velocidade impressionante e design elegante superaram minhas expectativas. A tela HD é nítida, proporcionando uma experiência visual incrível. O teclado é confortável, e a bateria tem uma durabilidade surpreendente. Além disso, o processador oferece desempenho excepcional para multitarefas. Estou muito satisfeito com minha compra e definitivamente recomendo o Lenovo G40-70 a quem procura um laptop confiável e eficiente.\""
      ],
      "metadata": {
        "id": "i72_MH7ttiYi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto_negativo = \"Infelizmente, minha experiência com o Lenovo G40-70 tem sido decepcionante. A performance do processador não atende às minhas necessidades, frequentemente apresentando lentidão em tarefas simples. A duração da bateria também é abaixo da média, exigindo recargas frequentes. A construção do laptop parece frágil, e alguns componentes parecem de qualidade inferior. Além disso, o aquecimento excessivo é uma preocupação constante. Infelizmente, não posso recomendar o Lenovo G40-70 com base na minha experiência insatisfatória.\""
      ],
      "metadata": {
        "id": "eOMxVayYtqZ8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto_neutro = \"O Lenovo G40-70 oferece um desempenho razoável para tarefas diárias. A tela e o teclado são aceitáveis, mas não impressionam. A durabilidade da bateria é mediana, exigindo recargas frequentes. O design é simples, e a construção parece sólida o suficiente. O processador atende às necessidades básicas, mas pode apresentar lentidão em multitarefas. A relação custo-benefício é equilibrada, considerando o preço. Em resumo, o Lenovo G40-70 é uma opção aceitável para usuários casuais, mas pode deixar a desejar para aqueles que buscam desempenho e recursos mais avançados.\""
      ],
      "metadata": {
        "id": "dGLJwQbgtvvQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    texto_positivo,\n",
        "    texto_negativo,\n",
        "    texto_neutro\n",
        "]"
      ],
      "metadata": {
        "id": "lWEjnNaXtQCx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora chamamos o método de análise passando os textos:"
      ],
      "metadata": {
        "id": "5qTmVoWLtz4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analysis_with_opinion_mining_example(client, documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "DMIwypGSt4hv",
        "outputId": "3e106152-8f83-480a-9141-0238e8ed0dde"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ClientAuthenticationError",
          "evalue": "(401) The Request text analysis over a collection of documents. Operation under Microsoft Cognitive Language Service is not supported with the current subscription key and pricing tier SpeechServices.S0.\nCode: 401\nMessage: The Request text analysis over a collection of documents. Operation under Microsoft Cognitive Language Service is not supported with the current subscription key and pricing tier SpeechServices.S0.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientAuthenticationError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/ai/textanalytics/_text_analytics_client.py\u001b[0m in \u001b[0;36manalyze_sentiment\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    990\u001b[0m                     \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAnalyzeSentimentResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentError\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                     self._client.analyze_text(\n\u001b[0m\u001b[1;32m    992\u001b[0m                         body=models.AnalyzeTextSentimentAnalysisInput(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/ai/textanalytics/_generated/_operations_mixin.py\u001b[0m in \u001b[0;36manalyze_text\u001b[0;34m(self, body, show_stats, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mmixin_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmixin_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/core/tracing/decorator.py\u001b[0m in \u001b[0;36mwrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspan_impl_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/ai/textanalytics/_generated/v2022_05_01/operations/_text_analytics_client_operations.py\u001b[0m in \u001b[0;36manalyze_text\u001b[0;34m(self, body, show_stats, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mmap_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailsafe_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mErrorResponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/core/exceptions.py\u001b[0m in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientAuthenticationError\u001b[0m: (401) The Request text analysis over a collection of documents. Operation under Microsoft Cognitive Language Service is not supported with the current subscription key and pricing tier SpeechServices.S0.\nCode: 401\nMessage: The Request text analysis over a collection of documents. Operation under Microsoft Cognitive Language Service is not supported with the current subscription key and pricing tier SpeechServices.S0.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mClientAuthenticationError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a29af0b372a2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_analysis_with_opinion_mining_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-fd66cb53bd4f>\u001b[0m in \u001b[0;36msentiment_analysis_with_opinion_mining_example\u001b[0;34m(client, documents)\u001b[0m\n\u001b[1;32m      5\u001b[0m     ] '''\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_opinion_mining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdoc_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/core/tracing/decorator.py\u001b[0m in \u001b[0;36mwrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mspan_impl_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspan_impl_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/ai/textanalytics/_validate.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# the latest version is selected, we assume all features supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mselected_api_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mVERSIONS_SUPPORTED\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mversion_method_added\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mversion_method_added\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mselected_api_version\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/ai/textanalytics/_text_analytics_client.py\u001b[0m in \u001b[0;36manalyze_sentiment\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             )\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHttpResponseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mprocess_http_response_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     def _analyze_result_callback(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/ai/textanalytics/_response_handlers.py\u001b[0m in \u001b[0;36mprocess_http_response_error\u001b[0;34m(error)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mraise_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResourceNotFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCSODataV4Format\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientAuthenticationError\u001b[0m: (401) The Request text analysis over a collection of documents. Operation under Microsoft Cognitive Language Service is not supported with the current subscription key and pricing tier SpeechServices.S0.\nCode: 401\nMessage: The Request text analysis over a collection of documents. Operation under Microsoft Cognitive Language Service is not supported with the current subscription key and pricing tier SpeechServices.S0."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O erro acima ocorreu pois esse serviço não é suportado para minha chave de inscrição e tipo de preço atual."
      ],
      "metadata": {
        "id": "9SKZhGABvD6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para resolver, criei outro recurso de linguagem utilizando o Escalão de preço\n",
        "Free F0 (5K Transactions per 30 days). Lembre-se de executar a função de autenticação novamente após atualizar a chave e o ponto final."
      ],
      "metadata": {
        "id": "tn4OsHV7vih_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando novamente:"
      ],
      "metadata": {
        "id": "WnMZ8ePqvq5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analysis_with_opinion_mining_example(client, documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJSvgpc9vRnR",
        "outputId": "2f005d91-2af3-45bd-91c2-5ef4efc1418d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Sentiment: mixed\n",
            "Overall scores: positive=0.43; neutral=0.04; negative=0.53 \n",
            "\n",
            "Sentence: The food and service were unacceptable. \n",
            "Sentence sentiment: negative\n",
            "Sentence score:\n",
            "Positive=0.00\n",
            "Neutral=0.01\n",
            "Negative=0.99\n",
            "\n",
            "......'negative' target 'food'\n",
            "......Target score:\n",
            "......Positive=0.01\n",
            "......Negative=0.99\n",
            "\n",
            "......'negative' assessment 'unacceptable'\n",
            "......Assessment score:\n",
            "......Positive=0.01\n",
            "......Negative=0.99\n",
            "\n",
            "......'negative' target 'service'\n",
            "......Target score:\n",
            "......Positive=0.01\n",
            "......Negative=0.99\n",
            "\n",
            "......'negative' assessment 'unacceptable'\n",
            "......Assessment score:\n",
            "......Positive=0.01\n",
            "......Negative=0.99\n",
            "\n",
            "\n",
            "\n",
            "Sentence: The concierge was nice, however.\n",
            "Sentence sentiment: positive\n",
            "Sentence score:\n",
            "Positive=0.86\n",
            "Neutral=0.08\n",
            "Negative=0.07\n",
            "\n",
            "......'positive' target 'concierge'\n",
            "......Target score:\n",
            "......Positive=1.00\n",
            "......Negative=0.00\n",
            "\n",
            "......'positive' assessment 'nice'\n",
            "......Assessment score:\n",
            "......Positive=1.00\n",
            "......Negative=0.00\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sucesso!"
      ],
      "metadata": {
        "id": "yIlzB750y0gT"
      }
    }
  ]
}